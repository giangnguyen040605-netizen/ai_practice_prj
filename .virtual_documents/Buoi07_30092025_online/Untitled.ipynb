





import pandas as pd
import numpy as np
import random as rnd
import matplotlib.pyplot as plt
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score
from sklearn import metrics
from sklearn.model_selection import train_test_split
from sklearn import tree
from sklearn import datasets





# Load dataset
dataset = datasets.load_wine()
X = dataset.data; y = dataset.target
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)


data_df = pd.DataFrame(X, columns=dataset.feature_names)
data_df





model = DecisionTreeClassifier(max_depth=4, )
model.fit(X_train, y_train)





y_pred = model.predict(X_test)
print(f"Classification report for DecisionTree:\n"
f"{metrics.classification_report(y_test, y_pred)}\n")


from sklearn.metrics import ConfusionMatrixDisplay
import matplotlib.pyplot as plt

# Vẽ ma trận nhầm lẫn (confusion matrix)
plt.figure(figsize=(5, 5))
ax = plt.gca()

disp = ConfusionMatrixDisplay.from_estimator(model, X_test, y_test, ax=ax)
disp.ax_.set_title("Confusion Matrix", fontsize=15)

plt.show()


from sklearn import tree
import matplotlib.pyplot as plt

# Vẽ cây quyết định
fig, ax = plt.subplots(figsize=(20, 5), dpi=500)

tree.plot_tree(
    model,
    feature_names=getattr(dataset, "feature_names", None),
    class_names=[str(cls) for cls in getattr(dataset, "target_names", [])],
    filled=True,
    ax=ax
)

plt.title("Decision Tree Visualization", fontsize=15)
plt.show()





# Plot the decision boundary
n_classes = 3
plot_colors = "ryb"
plot_step = 0.02

font = {'size'  : 25}
plt.figure(figsize=(30, 20))
plt.suptitle("Decision surface of a decision tree using paired features", **{'size': 30})

for pairidx, pair in enumerate([[0, 1], [0, 2], [0, 3],
                                [1, 2], [1, 3], [2, 3]]):
    plt.subplot(2, 3, pairidx + 1)
    X = X_train[:, pair]
    clf = DecisionTreeClassifier().fit(X, y_train)
    
    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1
    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1
    xx, yy = np.meshgrid(np.arange(x_min, x_max, plot_step),
                         np.arange(y_min, y_max, plot_step))
    plt.tight_layout(h_pad=0.5, w_pad=0.5, pad=2.5)
    
    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])
    Z = Z.reshape(xx.shape)
    cs = plt.contourf(xx, yy, Z, cmap=plt.cm.RdYlBu)
    
    plt.xlabel(dataset.feature_names[pair[0]], **font)
    plt.ylabel(dataset.feature_names[pair[1]], **font)
    
# Show the training points
    for i, color in zip(range(n_classes), plot_colors):
        idx = np.where(y_train == i)
        plt.scatter(X[idx, 0], X[idx, 1], c=color, label=dataset.target_names[i],
                    cmap=plt.cm.RdYlBu, edgecolor='black', s=30)
    plt.legend(loc='lower right', borderpad=0, handletextpad=0)






